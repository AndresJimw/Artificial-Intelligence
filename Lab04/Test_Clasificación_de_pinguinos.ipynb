{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YAKTzmy37r3"
      },
      "source": [
        "Autor: Brandon Andrés Jiménez Nieto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP-7yoX337r9"
      },
      "source": [
        "# **Prueba práctica:**  \n",
        "## Clasificación de Pinguinos de la Isla Palmer con un perceptrón multicapa (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0yZGx5V37r-"
      },
      "source": [
        "### **Objetivo y alcance del trabajo:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXxCcbOH37r-"
      },
      "source": [
        "**Objetivo:**\n",
        "\n",
        "El objetivo de este Jupyter Notebook es desarrollar y evaluar un modelo de clasificación utilizando un Perceptrón Multicapa (MLP). El modelo se entrenará utilizando un conjunto de datos de entrenamiento y luego se utilizará para hacer predicciones en un conjunto de datos de prueba.\n",
        "\n",
        "**Alcance:**\n",
        "\n",
        "Este Jupyter Notebook cubrirá los siguientes aspectos:\n",
        "\n",
        "1. Importación de las bibliotecas necesarias.\n",
        "2. Carga y exploración inicial de los datos.\n",
        "3. Preprocesamiento de los datos, si es necesario.\n",
        "4. División de los datos en conjuntos de entrenamiento y prueba.\n",
        "5. Creación de un MLPClassifier.\n",
        "6. Entrenamiento del MLPClassifier con el conjunto de entrenamiento.\n",
        "7. Uso del MLPClassifier entrenado para hacer predicciones en el conjunto de prueba.\n",
        "8. Evaluación del rendimiento del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCn-gzEf37r_"
      },
      "source": [
        "El conjunto de datos de Palmer Penguins fue introducido en 2020 por Allison Horst, Alison Hill y Kristen Gorman. Este conjunto de datos es a menudo utilizado para tareas de clasificación en aprendizaje automático.\n",
        "\n",
        "El conjunto de datos contiene 344 pingüinos observados en tres diferentes islas del archipiélago de Palmer, en la Antártida. Los datos fueron recogidos por el proyecto Palmer Long Term Ecological Research y la Fundación Nacional para la Ciencia de los Estados Unidos.\n",
        "\n",
        "Cada pingüino se clasifica en una de las tres especies: Adelie, Chinstrap y Gentoo. Para cada pingüino, el conjunto de datos incluye siete características:\n",
        "\n",
        "1. Especie: Adelie, Chinstrap, Gentoo.\n",
        "2. Isla: Torgersen, Biscoe, Dream.\n",
        "3. Longitud del pico (mm).\n",
        "4. Profundidad del pico (mm).\n",
        "5. Longitud de la aleta (mm).\n",
        "6. Masa corporal (g).\n",
        "7. Sexo: masculino, femenino.\n",
        "\n",
        "El objetivo principal al trabajar con este conjunto de datos es a menudo construir un modelo de clasificación que pueda predecir la especie de un pingüino basándose en las características que se tienen en la base de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNyNN2U_37sA"
      },
      "source": [
        "### **Fase I:** Carga y procesamiento de la base de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TuCLqtWC37sB"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías necesarias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZsewenVs37sE"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>culmen_length_mm</th>\n",
              "      <th>culmen_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>MALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>FEMALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>FEMALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>FEMALE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
              "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
              "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
              "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
              "3  Adelie  Torgersen               NaN              NaN                NaN   \n",
              "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
              "\n",
              "   body_mass_g     sex  \n",
              "0       3750.0    MALE  \n",
              "1       3800.0  FEMALE  \n",
              "2       3250.0  FEMALE  \n",
              "3          NaN     NaN  \n",
              "4       3450.0  FEMALE  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cargamos la base de datos 'palmer_penguins.csv' en un DataFrame de Pandas de nombre 'pinguinos'\n",
        "pinguinos = pd.read_csv('D:/Archivos de Usuario/Documents/Artificial-Intelligence/Datasets/palmer_penguins.csv')\n",
        "\n",
        "# Mostremos las primeras 5 filas de la base de datos\n",
        "pinguinos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "snOVPu-Q37sE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "species               0\n",
              "island                0\n",
              "culmen_length_mm      2\n",
              "culmen_depth_mm       2\n",
              "flipper_length_mm     2\n",
              "body_mass_g           2\n",
              "sex                  10\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Usamos el método 'isnull()' para identificar los valores nulos y el método 'sum()' para sumarlos\n",
        "pinguinos.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6jCFsqQL37sF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>culmen_length_mm</th>\n",
              "      <th>culmen_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>MALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>FEMALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>FEMALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>FEMALE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adelie</td>\n",
              "      <td>Torgersen</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>MALE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
              "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
              "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
              "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
              "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
              "5  Adelie  Torgersen              39.3             20.6              190.0   \n",
              "\n",
              "   body_mass_g     sex  \n",
              "0       3750.0    MALE  \n",
              "1       3800.0  FEMALE  \n",
              "2       3250.0  FEMALE  \n",
              "4       3450.0  FEMALE  \n",
              "5       3650.0    MALE  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Usamos el método 'dropna()' para eliminar las filas con valores nulos del DataFrame 'pinguinos'\n",
        "pinguinos = pinguinos.dropna()\n",
        "\n",
        "# Usamos el método 'head()' para mostrar las primeras 5 filas de la base de datos\n",
        "pinguinos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GFmtsKgl37sF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['MALE', 'FEMALE', '.'], dtype=object)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Usamos el método 'unique()' para encontrar los valores únicos en la columna 'sex'\n",
        "pinguinos['sex'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ydElWnbQ37sG"
      },
      "outputs": [],
      "source": [
        "# Eliminamos las filas con el valor '.' en la columna 'sex' usando el método de filtrado por comparación negada '!='\n",
        "pinguinos = pinguinos[pinguinos['sex'] != '.']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-uNGyBS37sH"
      },
      "source": [
        "### **Fase II:** Preparamos los datos para ser usados en un perceptrón multicapa (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "rvq5326D37sH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>island</th>\n",
              "      <th>culmen_length_mm</th>\n",
              "      <th>culmen_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>56</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44</td>\n",
              "      <td>43</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>49</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>62</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>73</td>\n",
              "      <td>14</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  body_mass_g  \\\n",
              "0       2                41               56                  5           30   \n",
              "1       2                44               43                 10           32   \n",
              "2       2                50               49                 19           11   \n",
              "4       2                21               62                 17           18   \n",
              "5       2                43               73                 14           26   \n",
              "\n",
              "   sex  \n",
              "0    1  \n",
              "1    0  \n",
              "2    0  \n",
              "4    0  \n",
              "5    1  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aislamos las variables predictoras que son todas menos la variable objetivo\n",
        "# Usamos el método 'drop()' para eliminar la columna 'species' del DataFrame 'pinguinos'\n",
        "X = pinguinos.drop('species', axis=1)\n",
        "\n",
        "# Convertimos las variables categóricas en variables numéricas mediante el método 'LabelEncoder()'\n",
        "# Usamos el método 'apply()' para aplicar la función 'LabelEncoder().fit_transform' a cada columna de 'X'\n",
        "X = X.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "# Mostremos las primeras 5 filas de la base de datos\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "a851BDXj37sI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Adelie\n",
              "1    Adelie\n",
              "2    Adelie\n",
              "4    Adelie\n",
              "5    Adelie\n",
              "Name: species, dtype: object"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aislamos la variable objetivo 'species' en la variable 'y'\n",
        "y = pinguinos['species']\n",
        "\n",
        "# Mostramos las primeras 5 filas de la base de datos\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n3CgBsWx37sI"
      },
      "outputs": [],
      "source": [
        "# Dividimos los datos 'X' y 'y' en entrenamiento y prueba con el método 'train_test_split'\n",
        "# Usamos el 0.2 (20%) de los datos para prueba\n",
        "# Guardamos los datos de entrenamiento en las variables 'X_train' y 'y_train'\n",
        "# Guardamos los datos de prueba en las variables 'X_test' y 'y_test'\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC-7gxoh37sJ"
      },
      "source": [
        "### **Fase III:** Clasificación de pinguinos con un perceptrón multicapa (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U3dSJaJi37sJ",
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Adelie', 'Adelie', 'Chinstrap', 'Gentoo', 'Chinstrap', 'Adelie',\n",
              "       'Chinstrap', 'Gentoo', 'Chinstrap', 'Gentoo', 'Adelie', 'Adelie',\n",
              "       'Gentoo', 'Adelie', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
              "       'Adelie', 'Adelie', 'Adelie', 'Chinstrap', 'Adelie', 'Gentoo',\n",
              "       'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Chinstrap', 'Gentoo',\n",
              "       'Chinstrap', 'Chinstrap', 'Adelie', 'Gentoo', 'Adelie',\n",
              "       'Chinstrap', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap',\n",
              "       'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Gentoo', 'Chinstrap',\n",
              "       'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie',\n",
              "       'Gentoo', 'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap', 'Gentoo',\n",
              "       'Chinstrap', 'Adelie', 'Chinstrap', 'Adelie', 'Adelie',\n",
              "       'Chinstrap', 'Gentoo', 'Gentoo'], dtype='<U9')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creamos un clasificador de tipo MLPClassifier con 2 capas ocultas de 100 neuronas cada una\n",
        "# Usamos la función de activación 'relu' y el optimizador 'adam'\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), activation='relu', solver='adam')\n",
        "\n",
        "# Usamos el método 'fit()' para entrenar el clasificador\n",
        "# Entrenamos el clasificador con los datos de entrenamiento 'X_train' y 'y_train'\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predecimos las etiquetas de los datos de prueba 'X_test' usando el método 'predict()' del clasificador entrenado\n",
        "y_pred = mlp.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LL1L-ffB37sJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculamos la precisión del modelo de clasificación 'mlp' con el método 'accuracy_score'\n",
        "# Usamos los datos 'y_test' y 'y_pred' como argumentos de la función 'accuracy_score'\n",
        "# Guardamos el resultado en la variable 'accuracy'\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0A3BcaSE37sK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[25,  0,  0],\n",
              "       [ 0, 16,  0],\n",
              "       [ 0,  0, 26]], dtype=int64)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mostramos la matriz de confusión del modelo de clasificación 'mlp' con el método 'confusion_matrix'\n",
        "# Usamos los datos 'y_test' y 'y_pred' como argumentos de la función 'confusion_matrix'\n",
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Wtsj7NXj37sK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Adelie       1.00      1.00      1.00        25\n",
            "   Chinstrap       1.00      1.00      1.00        16\n",
            "      Gentoo       1.00      1.00      1.00        26\n",
            "\n",
            "    accuracy                           1.00        67\n",
            "   macro avg       1.00      1.00      1.00        67\n",
            "weighted avg       1.00      1.00      1.00        67\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Imprimimos el reporte de clasificación del modelo de clasificación 'mlp' con el método 'classification_report'\n",
        "# Usamos los datos 'y_test' y 'y_pred' como argumentos de la función 'classification_report'\n",
        "# Imprimimos el reporte de clasificación en la consola con la función 'print'\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CfEIDn1d37sL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Archivos de Usuario\\Documents\\Artificial-Intelligence\\ai_env\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['Adelie'], dtype='<U9')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hacemos una prueba de predicción de especie con valores de un nuevo pinguino (no visto por el modelo)\n",
        "# Creamos una lista con los valores de las variables predictoras del nuevo pinguino\n",
        "# Puedes usar estos valores de ejemplo o cambiarlos por los valores aleatorios de un nuevo pinguino:\n",
        "#   island = 1 (Biscoe)\n",
        "#   culmen_length_mm = 45\n",
        "#   culmen_depth_mm = 58\n",
        "#   flipper_length_mm = 11\n",
        "#   body_mass_g = 22\n",
        "#   sex = 0 (FEMALE)\n",
        "# Guardamos la lista en la variable 'nuevo_pinguino'\n",
        "nuevo_pinguino = [[1, 45, 58, 11, 22, 0]]\n",
        "\n",
        "# Hacemos una predicción de la especie del 'nuevo_pinguino' con el método 'predict' del modelo 'mlp'\n",
        "# Guardamos la predicción en la variable 'nueva_prediccion'\n",
        "nueva_prediccion = mlp.predict(nuevo_pinguino)\n",
        "nueva_prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zBQqB7UF37sL"
      },
      "outputs": [],
      "source": [
        "# Guardar los pesos (coeficientes) de las capas del modelo MLP en archivos CSV\n",
        "for i, coef in enumerate(mlp.coefs_):\n",
        "    np.savetxt(f\"pesos_capa_{i+1}.csv\", coef, delimiter=\",\")\n",
        "\n",
        "# Guardar los sesgos (bias) de las capas del modelo MLP en archivos CSV\n",
        "for i, intercept in enumerate(mlp.intercepts_):\n",
        "    np.savetxt(f\"sesgos_capa_{i+1}.csv\", intercept, delimiter=\",\")\n",
        "\n",
        "# Esto generará archivos pesos_capa_1.csv, pesos_capa_2.csv, etc., que contienen los pesos de cada capa del modelo.\n",
        "# Y archivos sesgos_capa_1.csv, sesgos_capa_2.csv, etc., que contienen los sesgos de cada capa del modelo.\n",
        "\n",
        "\n",
        "# Usar estos archivos en Excel para replicar la inferencia del modelo con el nuevo pinguino.\n",
        "\n",
        "# Nota 1: Asegúrate de que el modelo 'mlp' ya ha sido entrenado antes de ejecutar este código.\n",
        "# Nota 2: MLPClassifier usa ReLU en las capas ocultas y sigmoid en la salida (para clases binarias) ó softmax en la salida (si tienes más de 2 clases).\n",
        "# Nota 3: El orden de los logits de salida corresponde al orden alfabético de las clases en y. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Fase IV:** Reproducir la inferencia con los CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utilidades\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(z):\n",
        "    # z: vector (K,)\n",
        "    z = np.asarray(z, dtype=float)\n",
        "    z = z - np.max(z)  # estabilización numérica\n",
        "    e = np.exp(z)\n",
        "    return e / e.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar los pesos/sesgos exportados\n",
        "W1 = np.loadtxt(\"pesos_capa_1.csv\", delimiter=\",\")   # forma: (n_features, n_hidden1)\n",
        "b1 = np.loadtxt(\"sesgos_capa_1.csv\", delimiter=\",\")  # forma: (n_hidden1,)\n",
        "W2 = np.loadtxt(\"pesos_capa_2.csv\", delimiter=\",\")   # forma: (n_hidden1, n_hidden2)\n",
        "b2 = np.loadtxt(\"sesgos_capa_2.csv\", delimiter=\",\")  # forma: (n_hidden2,)\n",
        "\n",
        "# Capa de salida\n",
        "W3 = np.loadtxt(\"pesos_capa_3.csv\", delimiter=\",\")   # forma: (n_hidden2, n_classes)\n",
        "b3 = np.loadtxt(\"sesgos_capa_3.csv\", delimiter=\",\")  # forma: (n_classes,)\n",
        "\n",
        "# Preparación del vector\n",
        "x = np.array([1, 45, 58, 11, 22, 0], dtype=float)  # (island, culmen_length_mm, culmen_depth_mm, flipper_length_mm, body_mass_g, sex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Forward pass manual con ReLU en ocultas y Softmax en salida\n",
        "z1 = x @ W1 + b1              # (n_hidden1,)\n",
        "h1 = relu(z1)\n",
        "\n",
        "z2 = h1 @ W2 + b2             # (n_hidden2,)\n",
        "h2 = relu(z2)\n",
        "\n",
        "z3 = h2 @ W3 + b3             # (n_classes,)\n",
        "probs_np = softmax(z3)        # distribución de probas (Softmax)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orden de clases (alfabético) -> mlp.classes_: ['Adelie' 'Chinstrap' 'Gentoo']\n",
            "Probas (NumPy/CSV):           [1. 0. 0.]\n",
            "Probas (scikit-learn):         [1. 0. 0.]\n",
            "Coinciden (≈):  True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Archivos de Usuario\\Documents\\Artificial-Intelligence\\ai_env\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Comparar con scikit-learn para validar\n",
        "probs_sklearn = mlp.predict_proba([x])[0]\n",
        "\n",
        "print(\"Orden de clases (alfabético) -> mlp.classes_:\", mlp.classes_)\n",
        "print(\"Probas (NumPy/CSV):          \", np.round(probs_np, 6))\n",
        "print(\"Probas (scikit-learn):        \", np.round(probs_sklearn, 6))\n",
        "print(\"Coinciden (≈): \", np.allclose(probs_np, probs_sklearn, atol=1e-5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Formas de matrices/vectores:\n",
            "W1: (6, 100)  b1: (100,)\n",
            "W2: (100, 100)  b2: (100,)\n",
            "W3: (100, 3)  b3: (3,)\n",
            "x : (6,)  -> logits salida (z3): (3,)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFormas de matrices/vectores:\")\n",
        "print(\"W1:\", W1.shape, \" b1:\", b1.shape)\n",
        "print(\"W2:\", W2.shape, \" b2:\", b2.shape)\n",
        "print(\"W3:\", W3.shape, \" b3:\", b3.shape)\n",
        "print(\"x :\", x.shape,  \" -> logits salida (z3):\", z3.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Fase V:** Generar Excel para replicar la inferencia del MLP (ReLU + Softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Excel dinámico creado: mlp_penguins_inferencia.xlsx\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import xlsxwriter\n",
        "from xlsxwriter.utility import xl_rowcol_to_cell\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# pinguinos : DataFrame limpio\n",
        "# mlp       : MLPClassifier entrenado con todas las columnas label-encoded\n",
        "FEATURES = [\"island\", \"culmen_length_mm\", \"culmen_depth_mm\",\n",
        "            \"flipper_length_mm\", \"body_mass_g\", \"sex\"]\n",
        "\n",
        "# 1) Pesos/sesgos del modelo\n",
        "coefs = mlp.coefs_\n",
        "bias  = mlp.intercepts_\n",
        "W1, W2, W3 = coefs\n",
        "b1, b2, b3 = bias\n",
        "\n",
        "n_features = W1.shape[0]\n",
        "n_hidden1  = W1.shape[1]\n",
        "n_hidden2  = W2.shape[1]\n",
        "n_classes  = W3.shape[1]\n",
        "class_order = mlp.classes_.tolist()\n",
        "\n",
        "# 2) RE-construir LabelEncoder por CADA columna\n",
        "# (igual que con .apply(LabelEncoder().fit_transform))\n",
        "encoders = {}\n",
        "maps = {}       # col -> list[(valor, codigo)]\n",
        "for col in FEATURES:\n",
        "    le = LabelEncoder().fit(pinguinos[col])\n",
        "    encoders[col] = le\n",
        "    vals = le.classes_.tolist()\n",
        "    codes = le.transform(vals).tolist()\n",
        "    # emparejar preservando tipo: texto/num\n",
        "    pair_list = list(zip(vals, codes))\n",
        "    maps[col] = pair_list\n",
        "\n",
        "# Valores iniciales SEGUROS (deben existir en clases_ de cada encoder)\n",
        "# Usamos la moda de cada columna (si hay múltiples, tomamos la primera)\n",
        "init_values = []\n",
        "for col in FEATURES:\n",
        "    mode_val = pinguinos[col].mode(dropna=True).iloc[0]\n",
        "    # Garantizar tipo numérico donde aplique\n",
        "    if isinstance(mode_val, (int, float, np.integer, np.floating)):\n",
        "        init_values.append(float(mode_val))\n",
        "    else:\n",
        "        init_values.append(str(mode_val))\n",
        "\n",
        "# 3) Crear Excel\n",
        "excel_path = \"mlp_penguins_inferencia.xlsx\"\n",
        "if os.path.exists(excel_path):\n",
        "    os.remove(excel_path)\n",
        "\n",
        "wb = xlsxwriter.Workbook(excel_path)\n",
        "\n",
        "# Estilos\n",
        "fmt_title  = wb.add_format({\"bold\": True, \"font_size\": 12})\n",
        "fmt_header = wb.add_format({\"bold\": True, \"bg_color\": \"#EFEFEF\", \"border\": 1})\n",
        "fmt_border = wb.add_format({\"border\": 1})\n",
        "fmt_num    = wb.add_format({\"num_format\": \"0.000000\"})\n",
        "fmt_pct    = wb.add_format({\"num_format\": \"0.0%\"})\n",
        "fmt_ok     = wb.add_format({\"bg_color\": \"#E6F3E6\"})\n",
        "fmt_note   = wb.add_format({\"italic\": True, \"font_color\": \"#666666\"})\n",
        "\n",
        "# Helpers\n",
        "def cell_abs(sheet, r, c):\n",
        "    return f\"{sheet}!{xl_rowcol_to_cell(r, c, row_abs=True, col_abs=True)}\"\n",
        "\n",
        "def range_abs(sheet, r1, c1, r2, c2):\n",
        "    return f\"{sheet}!{xl_rowcol_to_cell(r1,c1,True,True)}:{xl_rowcol_to_cell(r2,c2,True,True)}\"\n",
        "\n",
        "# 4) Hoja Meta: clases y mapas por columna\n",
        "meta = wb.add_worksheet(\"Meta\")\n",
        "r = 0\n",
        "meta.write(r, 0, \"Autor:\", fmt_header); meta.write(r, 1, \"Brandon Andrés Jiménez Nieto\"); r += 2\n",
        "meta.write(r, 0, \"Clases (orden mlp.classes_):\", fmt_header); r += 1\n",
        "classes_row = r\n",
        "meta.write_row(classes_row, 0, class_order, fmt_border)\n",
        "r = classes_row + 2\n",
        "\n",
        "# Guardar posiciones (valor, código) por columna para usar en MATCH/INDEX\n",
        "map_pos = {}  # col -> (r_ini, c_val=0, r_fin, c_code=1)\n",
        "for col in FEATURES:\n",
        "    meta.write(r, 0, f\"Mapa '{col}' (valor→code)\", fmt_header); r += 1\n",
        "    meta.write_row(r, 0, [f\"{col}_valor\", f\"{col}_code\"], fmt_header); r += 1\n",
        "    r_ini = r\n",
        "    for val, code in maps[col]:\n",
        "        # Escribimos valor con el tipo correcto\n",
        "        if isinstance(val, (int, float, np.integer, np.floating)):\n",
        "            meta.write_number(r, 0, float(val), fmt_border)\n",
        "        else:\n",
        "            meta.write(r, 0, str(val), fmt_border)\n",
        "        meta.write_number(r, 1, int(code), fmt_border)\n",
        "        r += 1\n",
        "    r_fin = r - 1\n",
        "    map_pos[col] = (r_ini, 0, r_fin, 1)\n",
        "    r += 1  # línea en blanco entre mapas\n",
        "\n",
        "# 5) Hoja Pesos\n",
        "wsW = wb.add_worksheet(\"Pesos\")\n",
        "# W1\n",
        "wsW.write(0, 0, \"W1 (n_features x n_hidden1)\", fmt_title)\n",
        "for i in range(W1.shape[0]):\n",
        "    wsW.write_row(1 + i, 0, W1[i, :].tolist(), fmt_num)\n",
        "b1_title = 1 + W1.shape[0] + 1\n",
        "wsW.write(b1_title, 0, \"b1 (n_hidden1)\", fmt_title)\n",
        "b1_row = b1_title + 1\n",
        "wsW.write_row(b1_row, 0, b1.tolist(), fmt_num)\n",
        "\n",
        "# W2\n",
        "W2_title = b1_row + 2\n",
        "wsW.write(W2_title, 0, \"W2 (n_hidden1 x n_hidden2)\", fmt_title)\n",
        "for i in range(W2.shape[0]):\n",
        "    wsW.write_row(W2_title + 1 + i, 0, W2[i, :].tolist(), fmt_num)\n",
        "b2_title = W2_title + 1 + W2.shape[0] + 1\n",
        "wsW.write(b2_title, 0, \"b2 (n_hidden2)\", fmt_title)\n",
        "b2_row = b2_title + 1\n",
        "wsW.write_row(b2_row, 0, b2.tolist(), fmt_num)\n",
        "\n",
        "# W3\n",
        "W3_title = b2_row + 2\n",
        "wsW.write(W3_title, 0, \"W3 (n_hidden2 x n_classes)\", fmt_title)\n",
        "for i in range(W3.shape[0]):\n",
        "    wsW.write_row(W3_title + 1 + i, 0, W3[i, :].tolist(), fmt_num)\n",
        "b3_title = W3_title + 1 + W3.shape[0] + 1\n",
        "wsW.write(b3_title, 0, \"b3 (n_classes)\", fmt_title)\n",
        "b3_row = b3_title + 1\n",
        "wsW.write_row(b3_row, 0, b3.tolist(), fmt_num)\n",
        "\n",
        "# Rangos absolutos de Pesos\n",
        "W1_r1, W1_c1 = 1, 0\n",
        "W1_r2, W1_c2 = W1_r1 + W1.shape[0] - 1, W1_c1 + W1.shape[1] - 1\n",
        "W2_r1, W2_c1 = W2_title + 1, 0\n",
        "W2_r2, W2_c2 = W2_r1 + W2.shape[0] - 1, W2_c1 + W2.shape[1] - 1\n",
        "W3_r1, W3_c1 = W3_title + 1, 0\n",
        "W3_r2, W3_c2 = W3_r1 + W3.shape[0] - 1, W3_c1 + W3.shape[1] - 1\n",
        "\n",
        "# 6) Hoja Inputs + Forward\n",
        "ws = wb.add_worksheet(\"Inputs\")\n",
        "ws.write(0, 0, \"Inferencia MLP (ReLU + Softmax) — Palmer Penguins\", fmt_title)\n",
        "ws.write(1, 0, \"Cambia los inputs; la predicción se actualiza al instante.\", fmt_note)\n",
        "\n",
        "# 6.1 Inputs crudos (EDITABLES)\n",
        "ws.write(3, 0, \"Inputs crudos\", fmt_header)\n",
        "ws.write_row(4, 0, FEATURES, fmt_header)\n",
        "ws.write_row(5, 0, init_values, fmt_border)\n",
        "\n",
        "# Validación de lista para TODAS las columnas (por el LabelEncoded)\n",
        "for col in FEATURES:\n",
        "    r1, c1, r2, c2 = map_pos[col]\n",
        "    # los valores están en la columna A (0) del mapa\n",
        "    lst = f\"=Meta!$A${r1+1}:$A${r2+1}\"\n",
        "    j = FEATURES.index(col)\n",
        "    ws.data_validation(5, j, 5, j, {'validate': 'list', 'source': lst})\n",
        "\n",
        "# 6.2 Inputs codificados (lo que consumió el MLP al entrenar: códigos 0..k)\n",
        "ws.write(7, 0, \"Inputs codificados (TODAS las columnas fueron LabelEncoded)\", fmt_header)\n",
        "ws.write_row(8, 0, FEATURES, fmt_header)\n",
        "enc_row = 9\n",
        "\n",
        "def enc_formula_for(col, raw_cell):\n",
        "    r1, c1, r2, c2 = map_pos[col]\n",
        "    rng_val  = f\"Meta!$A${r1+1}:$A${r2+1}\"\n",
        "    rng_code = f\"Meta!$B${r1+1}:$B${r2+1}\"\n",
        "    # Código = INDEX(code_map, MATCH(valor_crudo, val_map, 0))\n",
        "    return f\"=INDEX({rng_code}, MATCH({raw_cell}, {rng_val}, 0))\"\n",
        "\n",
        "for j, col in enumerate(FEATURES):\n",
        "    raw_cell = xl_rowcol_to_cell(5, j)\n",
        "    ws.write_formula(enc_row, j, enc_formula_for(col, raw_cell), fmt_border)\n",
        "\n",
        "# 6.3 Forward pass (usa directamente la fila 'enc_row' como X)\n",
        "x_row_range = f\"{xl_rowcol_to_cell(enc_row, 0)}:{xl_rowcol_to_cell(enc_row, n_features-1)}\"\n",
        "\n",
        "# Capa 1\n",
        "ws.write(11, 0, \"Capa 1 — z1; h1=ReLU(z1)\", fmt_header)\n",
        "z1_hdr = 12; z1_row = 13\n",
        "ws.write_row(z1_hdr, 0, [f\"z1_{i+1}\" for i in range(n_hidden1)], fmt_header)\n",
        "for j in range(n_hidden1):\n",
        "    W1_col = range_abs(\"Pesos\", W1_r1, W1_c1 + j, W1_r2, W1_c1 + j)\n",
        "    b1_j   = cell_abs(\"Pesos\", b1_row, j)\n",
        "    ws.write_formula(z1_row, j, f\"=MMULT({x_row_range}, {W1_col}) + {b1_j}\", fmt_num)\n",
        "\n",
        "h1_hdr = z1_row + 2; h1_row = h1_hdr + 1\n",
        "ws.write_row(h1_hdr, 0, [f\"h1_{i+1}\" for i in range(n_hidden1)], fmt_header)\n",
        "for j in range(n_hidden1):\n",
        "    ws.write_formula(h1_row, j, f\"=MAX(0, {xl_rowcol_to_cell(z1_row, j)})\", fmt_num)\n",
        "\n",
        "# Capa 2\n",
        "ws.write(h1_row + 2, 0, \"Capa 2 — z2; h2=ReLU(z2)\", fmt_header)\n",
        "z2_hdr = h1_row + 3; z2_row = z2_hdr + 1\n",
        "ws.write_row(z2_hdr, 0, [f\"z2_{i+1}\" for i in range(n_hidden2)], fmt_header)\n",
        "\n",
        "h1_range = f\"{xl_rowcol_to_cell(h1_row,0)}:{xl_rowcol_to_cell(h1_row,n_hidden1-1)}\"\n",
        "for j in range(n_hidden2):\n",
        "    W2_col = range_abs(\"Pesos\", W2_r1, W2_c1 + j, W2_r2, W2_c1 + j)\n",
        "    b2_j   = cell_abs(\"Pesos\", b2_row, j)\n",
        "    ws.write_formula(z2_row, j, f\"=MMULT({h1_range}, {W2_col}) + {b2_j}\", fmt_num)\n",
        "\n",
        "h2_hdr = z2_row + 2; h2_row = h2_hdr + 1\n",
        "ws.write_row(h2_hdr, 0, [f\"h2_{i+1}\" for i in range(n_hidden2)], fmt_header)\n",
        "for j in range(n_hidden2):\n",
        "    ws.write_formula(h2_row, j, f\"=MAX(0, {xl_rowcol_to_cell(z2_row, j)})\", fmt_num)\n",
        "\n",
        "# Salida + Softmax estable\n",
        "ws.write(h2_row + 2, 0, \"Salida — z3 (logits) y Probabilidades (Softmax)\", fmt_header)\n",
        "z3_hdr = h2_row + 3; z3_row = z3_hdr + 1\n",
        "ws.write_row(z3_hdr, 0, [f\"z3_{k+1}\" for k in range(n_classes)], fmt_header)\n",
        "\n",
        "h2_range = f\"{xl_rowcol_to_cell(h2_row,0)}:{xl_rowcol_to_cell(h2_row,n_hidden2-1)}\"\n",
        "for k in range(n_classes):\n",
        "    W3_col = range_abs(\"Pesos\", W3_r1, W3_c1 + k, W3_r2, W3_c1 + k)\n",
        "    b3_k   = cell_abs(\"Pesos\", b3_row, k)\n",
        "    ws.write_formula(z3_row, k, f\"=MMULT({h2_range}, {W3_col}) + {b3_k}\", fmt_num)\n",
        "\n",
        "probs_hdr = z3_row + 2\n",
        "ws.write_row(probs_hdr, 0, [f\"p({c})\" for c in class_order], fmt_header)\n",
        "nums_row   = probs_hdr + 1\n",
        "final_row  = nums_row + 1\n",
        "aux_max_col = n_classes + 2\n",
        "aux_den_col = n_classes + 3\n",
        "\n",
        "z3_vec = f\"{xl_rowcol_to_cell(z3_row,0)}:{xl_rowcol_to_cell(z3_row,n_classes-1)}\"\n",
        "ws.write(probs_hdr, aux_max_col, \"max_z3\", fmt_header)\n",
        "ws.write(probs_hdr, aux_den_col, \"den\", fmt_header)\n",
        "\n",
        "max_cell = xl_rowcol_to_cell(nums_row, aux_max_col)\n",
        "den_cell = xl_rowcol_to_cell(nums_row, aux_den_col)\n",
        "\n",
        "ws.write_formula(nums_row, aux_max_col, f\"=MAX({z3_vec})\", fmt_num)\n",
        "for k in range(n_classes):\n",
        "    ws.write_formula(nums_row, k, f\"=EXP({xl_rowcol_to_cell(z3_row,k)}-{max_cell})\", fmt_num)\n",
        "\n",
        "nums_range = f\"{xl_rowcol_to_cell(nums_row,0)}:{xl_rowcol_to_cell(nums_row,n_classes-1)}\"\n",
        "ws.write_formula(nums_row, aux_den_col, f\"=SUM({nums_range})\", fmt_num)\n",
        "\n",
        "for k in range(n_classes):\n",
        "    ws.write_formula(final_row, k, f\"={xl_rowcol_to_cell(nums_row,k)}/{den_cell}\", fmt_pct)\n",
        "\n",
        "# Predicción final\n",
        "pred_row = final_row + 2\n",
        "ws.write(pred_row, 0, \"Predicción (clase):\", fmt_header)\n",
        "classes_rng = f\"Meta!{xl_rowcol_to_cell(classes_row,0,True,True)}:{xl_rowcol_to_cell(classes_row,n_classes-1,True,True)}\"\n",
        "final_probs = f\"{xl_rowcol_to_cell(final_row,0)}:{xl_rowcol_to_cell(final_row,n_classes-1)}\"\n",
        "ws.write_formula(pred_row, 1, f\"=INDEX({classes_rng}, MATCH(MAX({final_probs}), {final_probs}, 0))\", fmt_ok)\n",
        "\n",
        "wb.close()\n",
        "print(f\"[OK] Excel dinámico creado: {excel_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](image-1.png)\n",
        "![alt text](image-3.png)\n",
        "![alt text](image-4.png)\n",
        "![alt text](image-5.png)\n",
        "![alt text](image-6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](image-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![alt text](image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZN_bud_37sM"
      },
      "source": [
        "**Useful Resources:**\n",
        "- https://support.microsoft.com/es-es/office/función-mmult-40593ed7-a3cd-4b6b-b9a3-e4ad3c7245eb"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
